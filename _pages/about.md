---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Ph.D. candidate in Computer Science at University of Southern California, starting in 2019. I am very fortunate to be advised by Prof. [Ram Nevatia](https://sites.usc.edu/iris-cvlab/professor-ram-nevatia/).
My research interest lies in the area of multimodal perception with vision and language, including large-scale vision-language transformers, and compositional zero-shot learning. I am now especially interested in Multimodal Large Language Models <strong>(LLMs)</strong> towards Artificial General Intelligence <strong>(AGI)</strong>.

I am currently interning at Microsoft Research Redmond, mentored by [Vibhav Vineet](https://vibhav-vineet.github.io/). In 2021 and 2022, I spent two wonderful summers as a Applied Scientist Intern at Amazon Alexa AI, working with [Rakesh Chada](https://www.amazon.science/author/rakesh-chada) and [Yue (Rex) Wu](https://scholar.google.com/citations?user=fONV3IgAAAAJ&hl=en).

Prior to USC, I was a Master student at University of Michigan, Ann Arbor, where I worked with Prof. [David Fouhey](https://web.eecs.umich.edu/~fouhey/) and Prof. [Jia Deng](https://www.cs.princeton.edu/~jiadeng/). I received my Bachelor's degree from Tsinghua University in 2017. During my undergrad time, I worked with [Prof. Shi-Min Hu](https://cg.cs.tsinghua.edu.cn/shimin.htm).

<font color="#ff0000">I am graduating in 2023 and now actively looking for full-time positions in computer vision, machine learning and artificial intelligence. Please feel free to get in touch if there are any opportunities!</font>

<h1 id="publications"> Selected Publications (<a href="/publications/">Full List</a>)</h1>

<p><u>CAILA: Concept-Aware Intra-Layer Adapters for Compositional Zero-Shot Learning</u><br>
<strong>Zhaoheng Zheng</strong>, Haidong Zhu, and Ram Nevatia
<br> arXiv Preprint<br>
<a href="https://arxiv.org/abs/2305.16681" class="btn btn--success">Paper</a></p>

<p><u>PatchZero: Defending against Adversarial Patch Attacks by Detecting and Zeroing the Patch</u><br>
Ke Xu*, Yao Xiao*, <strong>Zhaoheng Zheng</strong>, Kaijie Cai, and Ram Nevatia
<br> WACV 2023<br>
<a href="https://arxiv.org/abs/2207.01795" class="btn btn--success">Paper</a></p>
<!-- <a href="https://github.com/TheShadow29/VidSitu" class="btn btn--warning">Code</a>
; <a href="https://vidsitu.org/" class="btn btn--danger">Website</a> -->

<p><u>FashionVLP: Vision Language Transformer for Fashion Retrieval with Feedback</u><br>
Sonam Goenka*, <strong>Zhaoheng Zheng*</strong>, Ayush Jaiswal, Rakesh Chada, Yue Wu, Pradeep Natarajan, and Varsha Hedau
<br> CVPR 2022<br>
<a href="https://www.amazon.science/publications/fashionvlp-vision-language-transformer-for-fashion-retrieval-with-feedback" class="btn btn--success">Paper</a></p>

<p><u>Improving Object Detection and Attribute Recognition by Feature Entanglement Reduction</u><br>
<strong>Zhaoheng Zheng</strong>, Arka Sadhu, and Ram Nevatia
<br> ICIP 2021<br>
<a href="https://arxiv.org/abs/2108.11501" class="btn btn--success">Paper</a></p>

<p><u>Image Based Cloth Changing System</u><br>
<strong>Zhaoheng Zheng</strong>, Hao-Tian Zhang, Fang-Lue Zhang, and Tai-Jiang Mu
<br> Computational Visual Media, 2017<br>
<a href="https://cs.stanford.edu/~haotianz/research/clothes_changing/clothes_changing.pdf" class="btn btn--success">Paper</a></p>

<p hidden><script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=WuTycU_gptD1_uRJMJF-BV4Q0VudvsyDQpgvA3okEYs&cl=ffffff&w=a"></script></p>